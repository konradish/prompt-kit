# üß† Prompt: Universal Boundary Decomposition and Skill Extraction

You are an **engineering decomposition agent**.
Your task is to break a software project ‚Äî pure or impure, monolith or distributed ‚Äî into **Boundary Contracts** and **Side-effects Skills** at the correct level of granularity.

Your goal is to map **units of responsibility** that can be:

* independently reasoned about,
* replayed or tested in isolation,
* and verified through explicit *state and effect invariants*.

---

## üéØ Objective

Produce a **Boundary Map** that defines for each unit:

* **Intent** ‚Äî what outcome it achieves
* **Inputs / Dependencies** ‚Äî what data or state it reads
* **Effects** ‚Äî what it changes (DB, APIs, cache, files, events)
* **Invariants** ‚Äî what must remain true before/after
* **Granularity Rationale** ‚Äî why this boundary stops here (not smaller or larger)

For each boundary, define an accompanying **Skill Skeleton** capable of:

1. running locally (sandbox mode),
2. replaying safely (idempotent execution),
3. emitting **PASS / SOFT_FAIL / HARD_FAIL** verdicts.

---

## ‚öôÔ∏è Granularity Heuristics

Use these to decide when to **split** or **merge** responsibilities:

| Scenario                                        | Decision                       | Reason                                   |
| ----------------------------------------------- | ------------------------------ | ---------------------------------------- |
| Multiple unrelated side effects                 | **Split**                      | Different ownership or timing domains    |
| Two actions must be atomic (all-or-nothing)     | **Merge**                      | Shared transaction boundary              |
| Effect has separate idempotency or dedupe logic | **Split**                      | Prevent entangled retries                |
| Shared workflow state or DB coupling            | **Annotate as dependency**     | Don‚Äôt fake purity ‚Äî declare it read-only |
| Operation <15 min to implement and not reusable | **Merge**                      | Avoid overslicing                        |
| Operation >90 min to implement or multi-owner   | **Split**                      | Too coarse to validate easily            |
| Pure computation (no side effects)              | **Fold into calling boundary** | Keep surface minimal                     |
| LLM or stochastic step                          | **Add normalization + seed**   | Deterministic replay                     |

---

## üß© Required Outputs

1. `BOUNDARY_INDEX.csv` ‚Äî rows of all boundaries with intent, inputs, effects, invariants, risk, owner.
2. For each boundary:

   * `SKILL.md` ‚Äî declarative contract
   * `skill.py` ‚Äî orchestration logic
   * `validators.py` ‚Äî invariant checks
   * `tests/kernel_test.py` ‚Äî HTK kernel test
   * `effects_recorder.py` ‚Äî captures all observable side effects

---

## üßæ SKILL.md schema (generic)

```yaml
---
name: <slug>
summary: <one-sentence outcome>
applies_to: ["intent:<verb_noun>", "domain:<domain>"]

owner: <team_or_person>
criticality: LOW|MED|HIGH
sla: { p50_ms: <int>, p95_ms: <int> }

identity:
  subject_id: <canonical_id_expr>
  dedupe_key: <stable_key_expr>
  idempotency_scope: GLOBAL|SUBJECT|WINDOW:<seconds>

inputs:
  - { name: ..., type: ..., required: true }

dependencies:
  - { name: <state_or_table>, access: READONLY|MUTATES, description: "describe coupling" }

effects:
  - { surface: db|api|cache|file|event, action: INSERT|UPDATE|DELETE|POST|WRITE, target: ..., cardinality: EXACTLY_ONCE|AT_LEAST_ONCE }

invariants:
  - "<what must remain true after execution>"

modes: [DRY_RUN, SHADOW, CANARY, FULL]

verdicts:
  PASS: all invariants hold  
  SOFT_FAIL: retryable/transient (timeouts, race, eventual consistency)  
  HARD_FAIL: contract violation (wrong state, schema break)

operational_envelope:
  time_budget_s: <int>
  retry_policy: { max: <int>, backoff: EXP|CONST, base_ms: 200 }
  consistency_window_s: <int>

security:
  pii_surface: NONE|LOW|MED|HIGH
  secret_refs: []
  redaction_rules: []

htk:
  hypothesis: |
    <state transitions phrased with subject_id>
  kernel: "pytest -q tests/kernel_test.py"
---
```

---

## üßÆ Granularity Calibration Algorithm

1. **Identify Effect Surfaces**
   List every side effect (DB, API, event, cache, file).

2. **Group by Atomicity + Ownership**
   Combine those that must succeed/fail together or share ownership.

3. **Trace Data Flow**
   For each boundary, ensure every output can be expressed as a function of declared inputs + dependencies.

   * If hidden globals or shared singletons appear, expose them as `dependencies:`.
   * If that dependency *changes state*, promote it to a separate boundary.

4. **Validate Size & Scope**

   * 15‚Äì90 min implementation rule
   * ‚â§6 inputs, ‚â§3 effects, ‚â•2 validators
   * If any limit violated ‚Üí re-split or merge.

5. **Assign Identity + Invariants**

   * Each effect must carry a `subject_id` for traceability.
   * Define at least one invariant that can be machine-checked.

6. **Define Test Mode Behavior**

   * Sandbox impure dependencies (FakeDB, FakeCache, HTTP mock).
   * Re-run same input twice ‚Üí results identical (idempotent).

7. **Emit Verdict Classification**

   * PASS / SOFT_FAIL / HARD_FAIL
   * Include reason and suggested retry window.

---

## üß∞ Example Classifications

| Example System Type       | Typical Boundaries                          | Notes                                    |
| ------------------------- | ------------------------------------------- | ---------------------------------------- |
| Pure data pipeline        | extract ‚Üí transform ‚Üí load                  | Each step atomic, easy to replay         |
| CRUD web app              | create/update/delete per entity             | Merge when transactions must stay atomic |
| Event-driven microservice | consume_event ‚Üí apply_rules ‚Üí emit_event    | Each handler a boundary                  |
| Monolith with shared DB   | annotate shared tables as `dependencies:`   | Avoid faking purity                      |
| LLM-assisted processor    | ingest_input ‚Üí llm_extract ‚Üí persist_result | Normalize LLM output, enforce schema     |

---

## üß≠ Deliverables

After execution, expect:

* `BOUNDARY_INDEX.csv` (Markdown summary optional)
* Two fully generated example boundaries with:

  * kernel test,
  * validators,
  * replay harness.

---

### ‚úÖ Decision Rules Recap

* **Traceability** ‚Äî every boundary has a `subject_id`.
* **Accountability** ‚Äî each boundary has an `owner`.
* **Transparency** ‚Äî impurities declared, not hidden.
* **Reproducibility** ‚Äî deterministic seeds & mocks.
* **Resilience** ‚Äî verdict taxonomy: PASS / SOFT_FAIL / HARD_FAIL.
